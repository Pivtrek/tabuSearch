warunek stopu: liczba iteracji, czas, liczba iteracji bez poprawy

skupić na efektywnym zapamiętywaniu listy tabu search - pamiętać indeksy zamienionych miast
i przeszukiwaniu, przeszukiwanie listy tabu search najważniejsze na liście!!!

do przeszukiwań można działać na wątkach

typowy błąd - brak sprawdzania, że ostatnio nie mamy poprawy -> utknięcie w jakimś miejscu,można wtedy kombinować, wrócić do wcześniejszego miejsca i pamiętać ostatnie przejście, żeby ponownie go nie wybrał

zapamiętujemy najlepsze rozwiązanie, a nie ostatnie miejsce w którym jesteśmy

można korzystać z losowości, ale należy powtórzyć wtedy kilka razy i sprawdzić jakie jest maksymalne rozwiązanie, minimalne, średnia

pewne fragmenty true, false -> badanie algorytmu pod kątem wybranych rozwiązań
potem porównanie w stosunku do wcześniej zaimplementowanych algorytmów

Przejrzeć rozwiązanie tabu search Glover.


Projekt:
1. Wybór rozw. pocz. : 2-opt, losowe(k-random)
2. stworzenie listy tabu
3. wygenerowanie otoczenia
4. odnalezienie najlepszego rozw. z otoczenia i umieszczenie go na liście tabu
5. ustalenie warunku końca (liczba iteracji, czas, liczba iteracji bez poprawy.

Co potrzebujemy:
- plik z generowaniem macierzy sąsiedztwa
- funkcje która wyznacza losową ścieżkę
- funkcja licząca długość ścieżki
- 2-opt

- globalna lista tabu 
- globalnie rozw. najlepsze znalezione dotychczas

- funkcja wyznaczająca sąsiedztwo(invert z 2-opt)
- funkcja celu z dodaniem rozw. do listy tabu
- funkcja przeszukiwania listy tabu
- funkcja sprawdzenia tabu czy nie za długa, jeśli tak to np. usuwanie najstarszego rozwiązania
- funkcja sprawdzająca warunek końca (jeśli potrzebny)
- mechanizm wykrywania stagnacji

Do zrobienia:
- implementacja tabulisty i jej efektywnego przeszukiwania - zrobiona wersja z hashmapą
- dodanie uniknięcia "zakleszczenia się algorytmu" ("ślepy zaułek", wszyscy sąsiedzi w tabu, duża liczba iteracji bez
  poprawy (np. 500)) - wtedy nawrót do ostatniego dobrego rozwiązania, należy pamiętać conajmniej jedno które było po nim,
  żeby nie pójść tam znowu, lub też wyszukiwać minimum lokalne
- dodanie kryterium aspiracji (gdy rozw. jest w tabu, ale jest lepsze od obecnego - jakoś tak :) )
- testy ("strojenie algorytmu") wykresy czasu, pamięci efektywności w zależności od tego co badamy, małe próbki, dobór:
    długości listy tabu, warunku stopu(różna liczba iteracji, czas, określona liczba iteracji bez poprawy), procent
    sąsiedztwa
- testy porównawcze dostrojonego algorytmu z wcześniejszymi, większe próbki (czas, pamięć, efektywność) - można wykorzystać
  częsciowo wcześniej zaimplementowane testy
- (opcjonalnie) porównanie wersji short term memory z long term memory
- (opcjonalnie) pokazać dlaczego używam dictionary